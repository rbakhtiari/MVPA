{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a0d7b8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this file, spot light search MVPA is applied on Z-stat files from first level analysis I have done on naive space, ART applied images, with each stimuli giving one Z-stat image.\n",
    "\n",
    "MPVA is applied for all voxels of the brain. For each participant, data is split into the number of runs, with data from one run is used for test, and the rest is used for training. \n",
    "\n",
    "## Future works\n",
    "Testing on various types of classifers, wokring on classifier performance are works to be done.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595ae782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from importlib import reload #import function \"reload\"\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import glob\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600e07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MVPA_func import SpherePoints, SphereValue, LoadAllNii, MVPA_FeatureExtraction, MVPA_Classification, LoopiFeatureDict, multi_run_wrapperLoopiFeatureDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c3d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc34d3d",
   "metadata": {},
   "source": [
    "### Load subject list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfba78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list_file='C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/subj_simultaneous.txt'\n",
    "subj_list=list()\n",
    "f = open(subj_list_file, 'r')\n",
    "line=f.readline()\n",
    "while line:\n",
    "    subj_list.append(line[0:-1])\n",
    "    oldline=line\n",
    "    line = f.readline()\n",
    "subj_list.pop()\n",
    "subj_list.append(oldline)\n",
    "f.close()\n",
    "Nsubj=len(subj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbeb2dc",
   "metadata": {},
   "source": [
    "### Load SPM.mat to extract experiment info\n",
    "This cell loads spm.mat file for each participant and from the data, extracts the number of runs, the path for each stat file, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da5fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: I don't know why the last item is repeated! but it doesn't make a misatke\n",
    "\n",
    "conditions=['Neu','Neg','Pos','Targ']\n",
    "ZstatInfo=pd.DataFrame(columns=['Subj','Run','Folder']+conditions)\n",
    "for subj in subj_list:\n",
    "    #print('Participant: '+subj)\n",
    "    # Zstat files and their condisitons are in SPM filesWe repeat loading in the dataframe to avoid dividing the onsets by 2 multiple times ...\n",
    "    SubjSPMFolder='C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/MRI_data/Analysis/SPM/'+subj+'/3cond_dist2/'\n",
    "    os.path.isdir(SubjSPMFolder)\n",
    "    myZstat=[]\n",
    "    \n",
    "    nRuns = len(os.listdir(SubjSPMFolder))\n",
    "    iRuns = 0\n",
    "    for myRun in os.listdir(SubjSPMFolder):\n",
    "        ZstatInfotmp=pd.DataFrame(columns=ZstatInfo.columns,index=[0])\n",
    "        ZstatInfotmp['Subj'][0]=subj\n",
    "        \n",
    "        RunSubjSPM=SubjSPMFolder+myRun+'/SPM.mat'\n",
    "        ZstatInfotmp['Folder'][0]=SubjSPMFolder+myRun+'/'\n",
    "\n",
    "        #print('   loading SPM.mat for '+myRun+'...')\n",
    "        mat = loadmat(RunSubjSPM)\n",
    "        mdata=mat['SPM'][0,0]\n",
    "        ndata=mdata['Sess'][0,0]\n",
    "        odata=ndata['U']\n",
    "        pdata=odata['name'][0]\n",
    "        ZstatNames=[pdata[i][0,0][0] for i in range(len(pdata))]\n",
    "        myZstat.append(ZstatNames)\n",
    "\n",
    "        ZstatInfotmp['Run'][0]=iRuns+1\n",
    "        old_ind=len(myZstat[0])+1\n",
    "        for iCond in reversed(conditions):    \n",
    "            Start_ind=myZstat[0].index(iCond+'_1')+1\n",
    "            #print(Start_ind)\n",
    "            ZstatInfotmp[iCond][0]=['spmT_'+str(val).zfill(4)+'.nii' for val in list(range(Start_ind, old_ind))]#list(range(Start_ind, old_ind))\n",
    "            old_ind=Start_ind\n",
    "        ZstatInfo=ZstatInfo.append(ZstatInfotmp,ignore_index=True)\n",
    "        iRuns = iRuns+1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fc8ea",
   "metadata": {},
   "source": [
    "### find Voxel dimension by openning one of the image files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42cc2107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 28)\n"
     ]
    }
   ],
   "source": [
    "MyZstat=ZstatInfo.loc[(ZstatInfo['Subj']==subj) & (ZstatInfo['Run']==1)]\n",
    "MyZstat.reset_index(inplace = True, drop = True)\n",
    "MyFile=MyZstat['Folder'][0]+MyZstat['Neu'][0][0]\n",
    "#print(MyFile)\n",
    "data = nib.load(MyFile).get_data()\n",
    "voxel_dims = data.shape\n",
    "print(voxel_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d478ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305.241091399992\n"
     ]
    }
   ],
   "source": [
    "# Calculate the spotlights voxels for all points and keep them in AllPoints \n",
    "start = timer()\n",
    "\n",
    "radius = 1 #spheres have radius 2\n",
    "tmpPoints = SpherePoints(np.array([26,26,16]) , radius, voxel_dims)\n",
    "AllZeroSphere = np.zeros((1,tmpPoints.shape[2]))\n",
    "AllZeroSpherePoints=np.zeros(tmpPoints.shape)\n",
    "cnt=0\n",
    "for MyCenter in itertools.product(range(0,voxel_dims[0]), range(0,voxel_dims[1]), range(0,voxel_dims[2])):\n",
    "    #print(MyCenter)\n",
    "    myPoints = SpherePoints(np.array(MyCenter) , radius, voxel_dims)\n",
    "    if myPoints.shape==(3,1,0): myPoints=AllZeroSpherePoints\n",
    "    if cnt==0:\n",
    "        AllPoints = np.array(myPoints,ndmin=4)\n",
    "        cnt=1\n",
    "    else:\n",
    "        AllPoints = np.concatenate((AllPoints,np.array(myPoints,ndmin=4)),axis=0)\n",
    "#     if myPoints.shape!=(3,1,0): sphereVal = data[myPoints[0],myPoints[1],myPoints[2]]\n",
    "#     else: sphereVal = AllZeroSphere\n",
    "        \n",
    "#    if myPoints.shape!=(0,): sphereVal = SphereValue(myPoints,data)\n",
    "#     if sphereVal.shape!=(0,): sphereValOut=\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "119cacb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630.47824\n",
      "[0.5269097222222222, 0.5873263888888889, 0.5022569444444444, 0, 0, 0.4072916666666667, 0.5145833333333333, 0.506076388888889, 0.63125, 0.5677083333333333]\n"
     ]
    }
   ],
   "source": [
    "# This code does classification based on spot light search, serial processing, slow\n",
    "start = timer()\n",
    "CLconditions=['Neu','Neg','Targ']\n",
    "radius = 1 #spheres radius\n",
    "\n",
    "\n",
    "##LinearSVC(random_state=0))\n",
    "clf = SVC(kernel='linear',probability=True)\n",
    "pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "\n",
    "subj_list_one=[subj_list[1]]; \n",
    "Nsubj=len(subj_list_one)\n",
    "all_performance = np.zeros(Nsubj)\n",
    "for i_sub, subj in enumerate(subj_list_one):\n",
    "    \n",
    "    ZstatInfoSubj=ZstatInfo.loc[ZstatInfo['Subj']==subj]\n",
    "    \n",
    "    Alldata=LoadAllNii(ZstatInfoSubj,CLconditions) # load Alldata\n",
    "         \n",
    "    DataArgDict= {'AllPoints': AllPoints,\n",
    "              'ZstatInfoSubj':ZstatInfoSubj ,\n",
    "              'CLconditions': CLconditions, \n",
    "              'Alldata': Alldata,\n",
    "              'pipeSpotLight':pipeSpotLight} \n",
    "    SpotLight_performance=np.zeros(AllPoints.shape[0])\n",
    "    for iFeature in range(AllPoints.shape[0]): #iFeature=40836, range(56500,56610):\n",
    "        SpotLight_performance[iFeature]= LoopiFeatureDict(iFeature,DataArgDict)\n",
    "\n",
    "end = timer()\n",
    "print(end-start)\n",
    "SpotLight_performance[56500:56610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9694b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229.17325809999602\n",
      "[0.4682291666666667, 0.562326388888889, 0.4998263888888889, 0, 0, 0.4109375, 0.5413194444444444, 0.49756944444444445, 0.6347222222222222, 0.6092013888888889]\n"
     ]
    }
   ],
   "source": [
    "# This code does classification based on spot light search, parallel processing, fast\n",
    "start = timer()\n",
    "CLconditions=['Neu','Neg','Targ']\n",
    "radius = 1 #spheres radius\n",
    "\n",
    "\n",
    "##LinearSVC(random_state=0))\n",
    "clf = SVC(kernel='linear',probability=True)\n",
    "pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "\n",
    "subj_list_one=[subj_list[1]]; \n",
    "Nsubj=len(subj_list_one)\n",
    "all_performance = np.zeros(Nsubj)\n",
    "for i_sub, subj in enumerate(subj_list_one):\n",
    "    \n",
    "    ZstatInfoSubj=ZstatInfo.loc[ZstatInfo['Subj']==subj]\n",
    "    \n",
    "    Alldata=LoadAllNii(ZstatInfoSubj,CLconditions) # load Alldata\n",
    "         \n",
    "    DataArgDict= {'AllPoints': AllPoints,\n",
    "              'ZstatInfoSubj':ZstatInfoSubj ,\n",
    "              'CLconditions': CLconditions, \n",
    "              'Alldata': Alldata,\n",
    "              'pipeSpotLight':pipeSpotLight} \n",
    "    SpotLight_performance=np.zeros(AllPoints.shape[0])\n",
    "    \n",
    "    aa1= range(AllPoints.shape[0])\n",
    "    aa2=[DataArgDict]*len(aa1)\n",
    "    aa=[*zip(aa1, aa2)]\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        pool = Pool(multiprocessing.cpu_count())\n",
    "        resultsN = pool.map(multi_run_wrapperLoopiFeatureDict,aa)\n",
    "\n",
    "end = timer()\n",
    "print(end-start)\n",
    "print(resultsN[56500:56510])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

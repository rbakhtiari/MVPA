{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a0d7b8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this file, spot light search MVPA is applied on Z-stat files from first level analysis I have done on naive space, ART applied images, with each stimuli giving one Z-stat image.\n",
    "PLUS: EEG measures are added to the classifers.\n",
    "\n",
    "MPVA is applied for all voxels of the brain. For each participant, data is split into the number of runs, with data from one run is used for test, and the rest is used for training. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595ae782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from importlib import reload #import function \"reload\"\n",
    "import sys\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import glob\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600e07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MVPA_func import SpherePoints, SphereValue, LoadAllNii, MVPA_FeatureExtraction, MVPA_Classification, LoopiFeatureDict, multi_run_wrapperLoopiFeatureDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c3d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc34d3d",
   "metadata": {},
   "source": [
    "### Load subject list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dfba78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list_file='C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/subj_simultaneous.txt'\n",
    "subj_list=list()\n",
    "f = open(subj_list_file, 'r')\n",
    "line=f.readline()\n",
    "while line:\n",
    "    subj_list.append(line[0:-1])\n",
    "    oldline=line\n",
    "    line = f.readline()\n",
    "subj_list.pop()\n",
    "subj_list.append(oldline)\n",
    "f.close()\n",
    "Nsubj=len(subj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3dde3",
   "metadata": {},
   "source": [
    "### Load Partipants' ERP measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "301f312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLERP=['P3','LPP']\n",
    "ERPMeasure=['Peak','Mean','Latency']\n",
    "\n",
    "desire_channel_P1name = []\n",
    "desire_channel_P3name = ['Cz']#, 'Pz', 'PCz','CL', 'CR', 'PL', 'PR']\n",
    "desire_channel_LPPname = ['Pz']#, 'PL','PR','T5','T6']\n",
    "\n",
    "\n",
    "timeseries_path='C:\\\\Users\\\\user\\\\Documents\\\\Reyhaneh\\\\EEG+fMRI\\\\EO\\\\EEG_preproc\\\\ts\\\\'\n",
    "# List the folders in the specified directory\n",
    "ALLERP=['P3','LPP']\n",
    "CSV_out=timeseries_path+\"ERP_measures.csv\"\n",
    "\n",
    "ERP_df = pd.read_csv(timeseries_path+\"ERP_measures.csv\") \n",
    "\n",
    "#List of EEG features to be used for classification (can be more/less but should have similar format: ERP_Site_Measure)\n",
    "EEG_features=['P3_Cz_Peak']#,'LPP_Pz_Latency']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbeb2dc",
   "metadata": {},
   "source": [
    "### Load SPM.mat to extract fMRI experiment info\n",
    "This cell loads spm.mat file for each participant and from the data, extracts the number of runs, the path for each stat file, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da5fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note 3: I don't know why the last item is repeated! but it doesn't make a misatke\n",
    "\n",
    "conditions=['Neu','Neg','Pos','Targ']\n",
    "ZstatInfo_file='ZstatInfo.csv'\n",
    "if not os.file.exists(ZstatInfo_file):\n",
    "    \n",
    "    ERP_heading=[]\n",
    "    for myERP in ALLERP:\n",
    "        desire_channel_ERP_name=getattr(sys.modules[__name__], f\"desire_channel_{myERP}name\")\n",
    "        for mySite in desire_channel_ERP_name:\n",
    "            for myERPMeasure in ERPMeasure:\n",
    "                #print(f'{myERP}_{mySite}_{myERPMeasure}')\n",
    "                ERP_heading.append(f'{myERP}_{mySite}_{myERPMeasure}')\n",
    "\n",
    "    ZstatInfo=pd.DataFrame(columns=['Subj','Run','Folder']+conditions+ [condition + '_'+ERP_h for condition in conditions if condition != 'Pos' for ERP_h in ERP_heading])\n",
    "    #subj_list=['ET_12102013']\n",
    "    for subj in subj_list:\n",
    "        #print('Participant: '+subj)\n",
    "        # Zstat files and their condisitons are in SPM filesWe repeat loading in the dataframe to avoid dividing the onsets by 2 multiple times ...\n",
    "        SubjSPMFolder='C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/MRI_data/Analysis/SPM/'+subj+'/3cond_dist2/'\n",
    "        os.path.isdir(SubjSPMFolder)\n",
    "        myZstat=[]\n",
    "\n",
    "        iRuns = 0\n",
    "        for myRun in os.listdir(SubjSPMFolder):\n",
    "            if (subj=='ET_12102013') & (myRun=='run01'): \n",
    "                continue  \n",
    "            ZstatInfotmp=pd.DataFrame(columns=ZstatInfo.columns,index=[0])\n",
    "            ZstatInfotmp['Subj'][0]=subj\n",
    "\n",
    "            RunSubjSPM=SubjSPMFolder+myRun+'/SPM.mat'\n",
    "            ZstatInfotmp['Folder'][0]=SubjSPMFolder+myRun+'/'\n",
    "\n",
    "            #print('   loading SPM.mat for '+myRun+'...')\n",
    "            mat = loadmat(RunSubjSPM)\n",
    "            mdata=mat['SPM'][0,0]\n",
    "            ndata=mdata['Sess'][0,0]\n",
    "            odata=ndata['U']\n",
    "            pdata=odata['name'][0]\n",
    "            ZstatNames=[pdata[i][0,0][0] for i in range(len(pdata))]\n",
    "            myZstat.append(ZstatNames)\n",
    "\n",
    "            ZstatInfotmp['Run'][0]=iRuns+1\n",
    "            old_ind=len(myZstat[iRuns])+1\n",
    "            for iCond in reversed(conditions):    \n",
    "                #print(iCond)\n",
    "                Start_ind=myZstat[iRuns].index(iCond+'_1')+1\n",
    "                Trial_iCond_len=old_ind-Start_ind+1\n",
    "                #print(Start_ind)\n",
    "                ZstatInfotmp[iCond][0]=['spmT_'+str(val).zfill(4)+'.nii' for val in list(range(Start_ind, old_ind))]#list(range(Start_ind, old_ind))\n",
    "\n",
    "                for myERP in ALLERP:\n",
    "                    desire_channel_ERP_name=getattr(sys.modules[__name__], f\"desire_channel_{myERP}name\")\n",
    "                    for mySite in desire_channel_ERP_name:\n",
    "                        for myERPMeasure in ERPMeasure:\n",
    "                           # print(f'{myERP}_{mySite}_{myERPMeasure}')\n",
    "                            if iCond != 'Pos':\n",
    "                                ERP_Cond=[]\n",
    "                                for iTrial in range(1,Trial_iCond_len):\n",
    "                                    RowVal=ERP_df.loc[(ERP_df['Subject_ID'] == subj) & (ERP_df['Run'] == myRun) & (ERP_df['ERP'] == myERP) & (ERP_df['Site'] == mySite) & (ERP_df['Condition']==iCond+'_'+str(iTrial)),myERPMeasure]\n",
    "                                    try:\n",
    "                                        ERP_Cond.append(RowVal.values[0])\n",
    "                                    except IndexError:\n",
    "                                        pass\n",
    "            #                     print(iCond)\n",
    "            #                     print(ERP_Cond)\n",
    "                                ZstatInfotmp[f'{iCond}_{myERP}_{mySite}_{myERPMeasure}'][0]=ERP_Cond\n",
    "                old_ind=Start_ind\n",
    "\n",
    "            ZstatInfo=ZstatInfo.append(ZstatInfotmp,ignore_index=True)\n",
    "            iRuns = iRuns+1\n",
    "            \n",
    "    ZstatInfo.to_csv('ZstatInfo.csv', index=False) \n",
    "else:\n",
    "    np.load(ZstatInfo_file,ZstatInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b100dcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some errors were detected !\n    Line #2 (got 165 columns instead of 25)\n    Line #3 (got 200 columns instead of 25)\n    Line #4 (got 200 columns instead of 25)\n    Line #5 (got 200 columns instead of 25)\n    Line #6 (got 200 columns instead of 25)\n    Line #7 (got 200 columns instead of 25)\n    Line #8 (got 200 columns instead of 25)\n    Line #9 (got 200 columns instead of 25)\n    Line #10 (got 200 columns instead of 25)\n    Line #11 (got 200 columns instead of 25)\n    Line #12 (got 200 columns instead of 25)\n    Line #13 (got 200 columns instead of 25)\n    Line #14 (got 200 columns instead of 25)\n    Line #15 (got 200 columns instead of 25)\n    Line #16 (got 200 columns instead of 25)\n    Line #17 (got 200 columns instead of 25)\n    Line #18 (got 200 columns instead of 25)\n    Line #19 (got 200 columns instead of 25)\n    Line #20 (got 200 columns instead of 25)\n    Line #21 (got 200 columns instead of 25)\n    Line #22 (got 200 columns instead of 25)\n    Line #23 (got 200 columns instead of 25)\n    Line #24 (got 200 columns instead of 25)\n    Line #25 (got 200 columns instead of 25)\n    Line #26 (got 200 columns instead of 25)\n    Line #27 (got 137 columns instead of 25)\n    Line #28 (got 137 columns instead of 25)\n    Line #29 (got 137 columns instead of 25)\n    Line #30 (got 137 columns instead of 25)\n    Line #31 (got 137 columns instead of 25)\n    Line #32 (got 137 columns instead of 25)\n    Line #33 (got 137 columns instead of 25)\n    Line #34 (got 137 columns instead of 25)\n    Line #35 (got 137 columns instead of 25)\n    Line #36 (got 137 columns instead of 25)\n    Line #37 (got 137 columns instead of 25)\n    Line #38 (got 137 columns instead of 25)\n    Line #39 (got 137 columns instead of 25)\n    Line #40 (got 137 columns instead of 25)\n    Line #41 (got 137 columns instead of 25)\n    Line #42 (got 200 columns instead of 25)\n    Line #43 (got 200 columns instead of 25)\n    Line #44 (got 200 columns instead of 25)\n    Line #45 (got 200 columns instead of 25)\n    Line #46 (got 200 columns instead of 25)\n    Line #47 (got 165 columns instead of 25)\n    Line #48 (got 200 columns instead of 25)\n    Line #49 (got 200 columns instead of 25)\n    Line #50 (got 200 columns instead of 25)\n    Line #51 (got 200 columns instead of 25)\n    Line #52 (got 200 columns instead of 25)\n    Line #53 (got 200 columns instead of 25)\n    Line #54 (got 200 columns instead of 25)\n    Line #55 (got 200 columns instead of 25)\n    Line #56 (got 200 columns instead of 25)\n    Line #57 (got 200 columns instead of 25)\n    Line #58 (got 200 columns instead of 25)\n    Line #59 (got 200 columns instead of 25)\n    Line #60 (got 200 columns instead of 25)\n    Line #61 (got 200 columns instead of 25)\n    Line #62 (got 200 columns instead of 25)\n    Line #63 (got 200 columns instead of 25)\n    Line #64 (got 200 columns instead of 25)\n    Line #65 (got 200 columns instead of 25)\n    Line #66 (got 200 columns instead of 25)\n    Line #67 (got 200 columns instead of 25)\n    Line #68 (got 200 columns instead of 25)\n    Line #69 (got 200 columns instead of 25)\n    Line #70 (got 200 columns instead of 25)\n    Line #71 (got 200 columns instead of 25)\n    Line #72 (got 200 columns instead of 25)\n    Line #73 (got 200 columns instead of 25)\n    Line #74 (got 200 columns instead of 25)\n    Line #75 (got 200 columns instead of 25)\n    Line #76 (got 200 columns instead of 25)\n    Line #77 (got 200 columns instead of 25)\n    Line #78 (got 200 columns instead of 25)\n    Line #79 (got 200 columns instead of 25)\n    Line #80 (got 200 columns instead of 25)\n    Line #81 (got 200 columns instead of 25)\n    Line #82 (got 200 columns instead of 25)\n    Line #83 (got 200 columns instead of 25)\n    Line #84 (got 200 columns instead of 25)\n    Line #85 (got 200 columns instead of 25)\n    Line #86 (got 200 columns instead of 25)\n    Line #87 (got 200 columns instead of 25)\n    Line #88 (got 200 columns instead of 25)\n    Line #89 (got 200 columns instead of 25)\n    Line #90 (got 200 columns instead of 25)\n    Line #91 (got 200 columns instead of 25)\n    Line #92 (got 137 columns instead of 25)\n    Line #93 (got 137 columns instead of 25)\n    Line #94 (got 137 columns instead of 25)\n    Line #95 (got 137 columns instead of 25)\n    Line #96 (got 137 columns instead of 25)\n    Line #97 (got 137 columns instead of 25)\n    Line #98 (got 137 columns instead of 25)\n    Line #99 (got 137 columns instead of 25)\n    Line #100 (got 200 columns instead of 25)\n    Line #101 (got 200 columns instead of 25)\n    Line #102 (got 200 columns instead of 25)\n    Line #103 (got 200 columns instead of 25)\n    Line #104 (got 200 columns instead of 25)\n    Line #105 (got 200 columns instead of 25)\n    Line #106 (got 200 columns instead of 25)\n    Line #107 (got 200 columns instead of 25)\n    Line #108 (got 200 columns instead of 25)\n    Line #109 (got 200 columns instead of 25)\n    Line #110 (got 137 columns instead of 25)\n    Line #111 (got 137 columns instead of 25)\n    Line #112 (got 137 columns instead of 25)\n    Line #113 (got 137 columns instead of 25)\n    Line #114 (got 137 columns instead of 25)\n    Line #115 (got 137 columns instead of 25)\n    Line #116 (got 137 columns instead of 25)\n    Line #117 (got 137 columns instead of 25)\n    Line #118 (got 200 columns instead of 25)\n    Line #119 (got 200 columns instead of 25)\n    Line #120 (got 200 columns instead of 25)\n    Line #121 (got 200 columns instead of 25)\n    Line #122 (got 200 columns instead of 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m ZstatInfo_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZstatInfo.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#np.load(ZstatInfo_file,ZstatInfo)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZstatInfo_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\npyio.py:2291\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;66;03m# Raise an exception ?\u001b[39;00m\n\u001b[0;32m   2290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m invalid_raise:\n\u001b[1;32m-> 2291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(errmsg)\n\u001b[0;32m   2292\u001b[0m \u001b[38;5;66;03m# Issue a warning ?\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2294\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(errmsg, ConversionWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Some errors were detected !\n    Line #2 (got 165 columns instead of 25)\n    Line #3 (got 200 columns instead of 25)\n    Line #4 (got 200 columns instead of 25)\n    Line #5 (got 200 columns instead of 25)\n    Line #6 (got 200 columns instead of 25)\n    Line #7 (got 200 columns instead of 25)\n    Line #8 (got 200 columns instead of 25)\n    Line #9 (got 200 columns instead of 25)\n    Line #10 (got 200 columns instead of 25)\n    Line #11 (got 200 columns instead of 25)\n    Line #12 (got 200 columns instead of 25)\n    Line #13 (got 200 columns instead of 25)\n    Line #14 (got 200 columns instead of 25)\n    Line #15 (got 200 columns instead of 25)\n    Line #16 (got 200 columns instead of 25)\n    Line #17 (got 200 columns instead of 25)\n    Line #18 (got 200 columns instead of 25)\n    Line #19 (got 200 columns instead of 25)\n    Line #20 (got 200 columns instead of 25)\n    Line #21 (got 200 columns instead of 25)\n    Line #22 (got 200 columns instead of 25)\n    Line #23 (got 200 columns instead of 25)\n    Line #24 (got 200 columns instead of 25)\n    Line #25 (got 200 columns instead of 25)\n    Line #26 (got 200 columns instead of 25)\n    Line #27 (got 137 columns instead of 25)\n    Line #28 (got 137 columns instead of 25)\n    Line #29 (got 137 columns instead of 25)\n    Line #30 (got 137 columns instead of 25)\n    Line #31 (got 137 columns instead of 25)\n    Line #32 (got 137 columns instead of 25)\n    Line #33 (got 137 columns instead of 25)\n    Line #34 (got 137 columns instead of 25)\n    Line #35 (got 137 columns instead of 25)\n    Line #36 (got 137 columns instead of 25)\n    Line #37 (got 137 columns instead of 25)\n    Line #38 (got 137 columns instead of 25)\n    Line #39 (got 137 columns instead of 25)\n    Line #40 (got 137 columns instead of 25)\n    Line #41 (got 137 columns instead of 25)\n    Line #42 (got 200 columns instead of 25)\n    Line #43 (got 200 columns instead of 25)\n    Line #44 (got 200 columns instead of 25)\n    Line #45 (got 200 columns instead of 25)\n    Line #46 (got 200 columns instead of 25)\n    Line #47 (got 165 columns instead of 25)\n    Line #48 (got 200 columns instead of 25)\n    Line #49 (got 200 columns instead of 25)\n    Line #50 (got 200 columns instead of 25)\n    Line #51 (got 200 columns instead of 25)\n    Line #52 (got 200 columns instead of 25)\n    Line #53 (got 200 columns instead of 25)\n    Line #54 (got 200 columns instead of 25)\n    Line #55 (got 200 columns instead of 25)\n    Line #56 (got 200 columns instead of 25)\n    Line #57 (got 200 columns instead of 25)\n    Line #58 (got 200 columns instead of 25)\n    Line #59 (got 200 columns instead of 25)\n    Line #60 (got 200 columns instead of 25)\n    Line #61 (got 200 columns instead of 25)\n    Line #62 (got 200 columns instead of 25)\n    Line #63 (got 200 columns instead of 25)\n    Line #64 (got 200 columns instead of 25)\n    Line #65 (got 200 columns instead of 25)\n    Line #66 (got 200 columns instead of 25)\n    Line #67 (got 200 columns instead of 25)\n    Line #68 (got 200 columns instead of 25)\n    Line #69 (got 200 columns instead of 25)\n    Line #70 (got 200 columns instead of 25)\n    Line #71 (got 200 columns instead of 25)\n    Line #72 (got 200 columns instead of 25)\n    Line #73 (got 200 columns instead of 25)\n    Line #74 (got 200 columns instead of 25)\n    Line #75 (got 200 columns instead of 25)\n    Line #76 (got 200 columns instead of 25)\n    Line #77 (got 200 columns instead of 25)\n    Line #78 (got 200 columns instead of 25)\n    Line #79 (got 200 columns instead of 25)\n    Line #80 (got 200 columns instead of 25)\n    Line #81 (got 200 columns instead of 25)\n    Line #82 (got 200 columns instead of 25)\n    Line #83 (got 200 columns instead of 25)\n    Line #84 (got 200 columns instead of 25)\n    Line #85 (got 200 columns instead of 25)\n    Line #86 (got 200 columns instead of 25)\n    Line #87 (got 200 columns instead of 25)\n    Line #88 (got 200 columns instead of 25)\n    Line #89 (got 200 columns instead of 25)\n    Line #90 (got 200 columns instead of 25)\n    Line #91 (got 200 columns instead of 25)\n    Line #92 (got 137 columns instead of 25)\n    Line #93 (got 137 columns instead of 25)\n    Line #94 (got 137 columns instead of 25)\n    Line #95 (got 137 columns instead of 25)\n    Line #96 (got 137 columns instead of 25)\n    Line #97 (got 137 columns instead of 25)\n    Line #98 (got 137 columns instead of 25)\n    Line #99 (got 137 columns instead of 25)\n    Line #100 (got 200 columns instead of 25)\n    Line #101 (got 200 columns instead of 25)\n    Line #102 (got 200 columns instead of 25)\n    Line #103 (got 200 columns instead of 25)\n    Line #104 (got 200 columns instead of 25)\n    Line #105 (got 200 columns instead of 25)\n    Line #106 (got 200 columns instead of 25)\n    Line #107 (got 200 columns instead of 25)\n    Line #108 (got 200 columns instead of 25)\n    Line #109 (got 200 columns instead of 25)\n    Line #110 (got 137 columns instead of 25)\n    Line #111 (got 137 columns instead of 25)\n    Line #112 (got 137 columns instead of 25)\n    Line #113 (got 137 columns instead of 25)\n    Line #114 (got 137 columns instead of 25)\n    Line #115 (got 137 columns instead of 25)\n    Line #116 (got 137 columns instead of 25)\n    Line #117 (got 137 columns instead of 25)\n    Line #118 (got 200 columns instead of 25)\n    Line #119 (got 200 columns instead of 25)\n    Line #120 (got 200 columns instead of 25)\n    Line #121 (got 200 columns instead of 25)\n    Line #122 (got 200 columns instead of 25)"
     ]
    }
   ],
   "source": [
    "ZstatInfo_file='ZstatInfo.csv'\n",
    "#np.load(ZstatInfo_file,ZstatInfo)\n",
    "data = np.genfromtxt(ZstatInfo_file, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ba0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZstatInfo_tmp=ZstatInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2bf84e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subj</th>\n",
       "      <th>Run</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Neu</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Targ</th>\n",
       "      <th>Neu_P3_Cz_Peak</th>\n",
       "      <th>Neu_P3_Cz_Mean</th>\n",
       "      <th>Neu_P3_Cz_Latency</th>\n",
       "      <th>...</th>\n",
       "      <th>Neg_P3_Cz_Latency</th>\n",
       "      <th>Neg_LPP_Pz_Peak</th>\n",
       "      <th>Neg_LPP_Pz_Mean</th>\n",
       "      <th>Neg_LPP_Pz_Latency</th>\n",
       "      <th>Targ_P3_Cz_Peak</th>\n",
       "      <th>Targ_P3_Cz_Mean</th>\n",
       "      <th>Targ_P3_Cz_Latency</th>\n",
       "      <th>Targ_LPP_Pz_Peak</th>\n",
       "      <th>Targ_LPP_Pz_Mean</th>\n",
       "      <th>Targ_LPP_Pz_Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ET_12102013</td>\n",
       "      <td>1</td>\n",
       "      <td>C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...</td>\n",
       "      <td>[spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...</td>\n",
       "      <td>[spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...</td>\n",
       "      <td>[spmT_0011.nii]</td>\n",
       "      <td>[spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...</td>\n",
       "      <td>[4.7565, 10.406, 5.8969, 13.177, 13.917]</td>\n",
       "      <td>[-2.4795084, 2.65940396, -5.191728133, 0.96931...</td>\n",
       "      <td>[288, 496, 484, 436, 540]</td>\n",
       "      <td>...</td>\n",
       "      <td>[516, 336, 464, 328, 464]</td>\n",
       "      <td>[19.689, 14.803, 20.733, 19.17, 4.5067]</td>\n",
       "      <td>[5.4839868, -2.047257067, 10.16479333, 5.85351...</td>\n",
       "      <td>[708, 812, 708, 684, 652]</td>\n",
       "      <td>[13.204, 2.2278, 0.53742, 6.0702, 17.849, 20.9...</td>\n",
       "      <td>[5.490772973, -3.250177861, -9.143535813, -1.1...</td>\n",
       "      <td>[356, 268, 468, 308, 540, 288, 516, 376, 512]</td>\n",
       "      <td>[11.789, 12.805, -11.566, 10.025, 11.778, 20.7...</td>\n",
       "      <td>[-0.033728133, -14.79068313, -18.34509333, -1....</td>\n",
       "      <td>[672, 944, 716, 920, 924, 828, 768, 784, 832]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ET_12102013</td>\n",
       "      <td>2</td>\n",
       "      <td>C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...</td>\n",
       "      <td>[spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...</td>\n",
       "      <td>[spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...</td>\n",
       "      <td>[spmT_0011.nii]</td>\n",
       "      <td>[spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...</td>\n",
       "      <td>[21.666, 2.082, 6.203, 18.759, 8.4982]</td>\n",
       "      <td>[12.28638133, -6.798790267, -8.072784, 5.27236...</td>\n",
       "      <td>[520, 300, 448, 544, 352]</td>\n",
       "      <td>...</td>\n",
       "      <td>[476, 416, 300, 476, 300]</td>\n",
       "      <td>[13.516, 9.5852, 15.951, -5.8196, 12.226]</td>\n",
       "      <td>[4.543109067, -5.40825916, 7.187302667, -16.71...</td>\n",
       "      <td>[760, 700, 912, 664, 844]</td>\n",
       "      <td>[15.382, 10.623, 19.378, 13.18, 7.5719, 17.824...</td>\n",
       "      <td>[3.604507333, 2.952521333, 10.97116267, 4.7187...</td>\n",
       "      <td>[268, 384, 288, 460, 528, 444, 352, 480, 432]</td>\n",
       "      <td>[8.2591, 12.787, 9.4401, 18.837, 8.0799, 7.799...</td>\n",
       "      <td>[-14.98742907, -3.310568201, -8.010133333, 1.9...</td>\n",
       "      <td>[916, 824, 932, 936, 784, 696, 856, 680, 908]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ET_12102013</td>\n",
       "      <td>3</td>\n",
       "      <td>C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...</td>\n",
       "      <td>[spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...</td>\n",
       "      <td>[spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...</td>\n",
       "      <td>[spmT_0011.nii]</td>\n",
       "      <td>[spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...</td>\n",
       "      <td>[10.541, 21.854, 14.335, 12.602, 17.776]</td>\n",
       "      <td>[-1.131931067, 12.782096, 4.802221793, 1.00837...</td>\n",
       "      <td>[496, 284, 480, 508, 396]</td>\n",
       "      <td>...</td>\n",
       "      <td>[396, 496, 376, 500, 500]</td>\n",
       "      <td>[12.613, 11.467, 20.775, 37.825, 21.961]</td>\n",
       "      <td>[-3.792235733, 0.318505267, 5.570956, 17.74137...</td>\n",
       "      <td>[684, 884, 764, 660, 676]</td>\n",
       "      <td>[11.223, 10.602, 14.046, 12.654, 22.341, 14.40...</td>\n",
       "      <td>[2.668363333, 0.992697333, 4.3212716, 2.790468...</td>\n",
       "      <td>[268, 476, 444, 540, 464, 368, 380, 348, 368]</td>\n",
       "      <td>[8.3593, 9.445, -7.4329, 26.584, 4.5528, 12.94...</td>\n",
       "      <td>[-2.17837112, -12.98541112, -24.736936, 10.269...</td>\n",
       "      <td>[876, 760, 820, 740, 820, 948, 936, 676, 864]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ET_12102013</td>\n",
       "      <td>4</td>\n",
       "      <td>C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...</td>\n",
       "      <td>[spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...</td>\n",
       "      <td>[spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...</td>\n",
       "      <td>[spmT_0011.nii]</td>\n",
       "      <td>[spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...</td>\n",
       "      <td>[22.759, 15.829, 21.62, 20.704, 7.0302]</td>\n",
       "      <td>[7.9550784, 2.9965892, 13.00924667, 10.98165, ...</td>\n",
       "      <td>[440, 328, 464, 448, 464]</td>\n",
       "      <td>...</td>\n",
       "      <td>[380, 468, 544, 360, 412]</td>\n",
       "      <td>[-5.8567, 19.269, 15.181, 0.026447, 9.8532]</td>\n",
       "      <td>[-17.93910267, 5.3266208, 2.012536707, -9.7525...</td>\n",
       "      <td>[800, 716, 736, 852, 652]</td>\n",
       "      <td>[9.3273, 15.912, 9.5864, 14.686, 5.5621, 10.86...</td>\n",
       "      <td>[-2.16354653, 6.6423792, 0.589601483, 7.341789...</td>\n",
       "      <td>[388, 508, 508, 300, 504, 524, 508, 396, 536]</td>\n",
       "      <td>[-2.2704, 20.702, 0.83205, 10.229, 9.0697, 59....</td>\n",
       "      <td>[-11.74187867, 8.154603013, -13.39265827, -7.6...</td>\n",
       "      <td>[924, 828, 872, 936, 660, 836, 848, 740, 852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ET_12102013</td>\n",
       "      <td>5</td>\n",
       "      <td>C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...</td>\n",
       "      <td>[spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...</td>\n",
       "      <td>[spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...</td>\n",
       "      <td>[spmT_0011.nii]</td>\n",
       "      <td>[spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...</td>\n",
       "      <td>[-0.31463, 11.5, 13.366, 10.971, 9.4683]</td>\n",
       "      <td>[-9.32181, 2.9781584, 7.61156, -2.425194373, 0...</td>\n",
       "      <td>[480, 468, 476, 540, 456]</td>\n",
       "      <td>...</td>\n",
       "      <td>[480, 496, 536, 448, 500]</td>\n",
       "      <td>[11.552, 7.454, 14.139, 22.385, 30.584]</td>\n",
       "      <td>[-1.818389333, -4.315699867, 3.7948524, 8.8629...</td>\n",
       "      <td>[704, 776, 852, 828, 748]</td>\n",
       "      <td>[17.776, 10.522, 15.671, 24.699, 23.455, 22.33...</td>\n",
       "      <td>[4.825973867, 4.16720756, 3.339279187, 9.86758...</td>\n",
       "      <td>[468, 524, 272, 480, 424, 360, 476, 496, 404]</td>\n",
       "      <td>[23.705, 9.9586, 15.324, 25.742, 2.6582, 19.15...</td>\n",
       "      <td>[4.17171284, -6.491420853, -1.072993067, 7.145...</td>\n",
       "      <td>[680, 876, 780, 700, 872, 708, 904, 908, 720]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ET_12102013</td>\n",
       "      <td>6</td>\n",
       "      <td>C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...</td>\n",
       "      <td>[spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...</td>\n",
       "      <td>[spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...</td>\n",
       "      <td>[spmT_0011.nii]</td>\n",
       "      <td>[spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...</td>\n",
       "      <td>[12.882, 6.1535, 9.2408, -8.3327, 9.989]</td>\n",
       "      <td>[3.48094328, -0.838196133, -1.76337968, -14.66...</td>\n",
       "      <td>[536, 424, 472, 368, 308]</td>\n",
       "      <td>...</td>\n",
       "      <td>[444, 468, 512, 548, 312]</td>\n",
       "      <td>[6.8689, -5.7977, 11.676, 5.4147, 17.426]</td>\n",
       "      <td>[-4.407986, -20.41518667, 0.888515333, -8.7165...</td>\n",
       "      <td>[752, 948, 732, 768, 760]</td>\n",
       "      <td>[20.765, 13.037, 20.928, 11.307, 24.376, 9.234...</td>\n",
       "      <td>[10.30210171, 4.131259147, 10.21560733, 3.7273...</td>\n",
       "      <td>[352, 332, 456, 284, 480, 452, 404, 484, 352]</td>\n",
       "      <td>[15.451, 29.78, 28.229, -2.1441, -5.1174, 32.7...</td>\n",
       "      <td>[-0.6861636, 5.514461333, 18.69056933, -18.209...</td>\n",
       "      <td>[876, 852, 900, 704, 704, 928, 812, 916, 928]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ET_12102013</td>\n",
       "      <td>7</td>\n",
       "      <td>C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...</td>\n",
       "      <td>[spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...</td>\n",
       "      <td>[spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...</td>\n",
       "      <td>[spmT_0011.nii]</td>\n",
       "      <td>[spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...</td>\n",
       "      <td>[11.628, 7.9444, 1.9218, 16.523, 7.9621]</td>\n",
       "      <td>[-1.03099728, 2.572337364, -5.372365467, 4.378...</td>\n",
       "      <td>[300, 352, 484, 484, 368]</td>\n",
       "      <td>...</td>\n",
       "      <td>[364, 404, 448, 480, 460]</td>\n",
       "      <td>[16.491, 7.6822, 11.852, 35.217, 20.611]</td>\n",
       "      <td>[1.6644732, -2.4791112, 1.861610987, 13.535673...</td>\n",
       "      <td>[792, 908, 828, 668, 708]</td>\n",
       "      <td>[17.259, 21.296, 17.153, 20.551, 13.59, 6.6623...</td>\n",
       "      <td>[1.868087333, 8.422179853, 11.01720133, 5.5208...</td>\n",
       "      <td>[500, 416, 408, 460, 380, 392, 352, 456, 504]</td>\n",
       "      <td>[14.382, 16.7, 11.894, 2.6002, 17.236, 5.3784,...</td>\n",
       "      <td>[1.581504933, 1.814372133, -3.000958933, -12.0...</td>\n",
       "      <td>[792, 880, 800, 664, 768, 896, 748, 808, 708]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Subj Run                                             Folder  \\\n",
       "0  ET_12102013   1  C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...   \n",
       "1  ET_12102013   2  C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...   \n",
       "2  ET_12102013   3  C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...   \n",
       "3  ET_12102013   4  C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...   \n",
       "4  ET_12102013   5  C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...   \n",
       "5  ET_12102013   6  C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...   \n",
       "6  ET_12102013   7  C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...   \n",
       "\n",
       "                                                 Neu  \\\n",
       "0  [spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...   \n",
       "1  [spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...   \n",
       "2  [spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...   \n",
       "3  [spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...   \n",
       "4  [spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...   \n",
       "5  [spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...   \n",
       "6  [spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...   \n",
       "\n",
       "                                                 Neg              Pos  \\\n",
       "0  [spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...  [spmT_0011.nii]   \n",
       "1  [spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...  [spmT_0011.nii]   \n",
       "2  [spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...  [spmT_0011.nii]   \n",
       "3  [spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...  [spmT_0011.nii]   \n",
       "4  [spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...  [spmT_0011.nii]   \n",
       "5  [spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...  [spmT_0011.nii]   \n",
       "6  [spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...  [spmT_0011.nii]   \n",
       "\n",
       "                                                Targ  \\\n",
       "0  [spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...   \n",
       "1  [spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...   \n",
       "2  [spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...   \n",
       "3  [spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...   \n",
       "4  [spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...   \n",
       "5  [spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...   \n",
       "6  [spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...   \n",
       "\n",
       "                             Neu_P3_Cz_Peak  \\\n",
       "0  [4.7565, 10.406, 5.8969, 13.177, 13.917]   \n",
       "1    [21.666, 2.082, 6.203, 18.759, 8.4982]   \n",
       "2  [10.541, 21.854, 14.335, 12.602, 17.776]   \n",
       "3   [22.759, 15.829, 21.62, 20.704, 7.0302]   \n",
       "4  [-0.31463, 11.5, 13.366, 10.971, 9.4683]   \n",
       "5  [12.882, 6.1535, 9.2408, -8.3327, 9.989]   \n",
       "6  [11.628, 7.9444, 1.9218, 16.523, 7.9621]   \n",
       "\n",
       "                                      Neu_P3_Cz_Mean  \\\n",
       "0  [-2.4795084, 2.65940396, -5.191728133, 0.96931...   \n",
       "1  [12.28638133, -6.798790267, -8.072784, 5.27236...   \n",
       "2  [-1.131931067, 12.782096, 4.802221793, 1.00837...   \n",
       "3  [7.9550784, 2.9965892, 13.00924667, 10.98165, ...   \n",
       "4  [-9.32181, 2.9781584, 7.61156, -2.425194373, 0...   \n",
       "5  [3.48094328, -0.838196133, -1.76337968, -14.66...   \n",
       "6  [-1.03099728, 2.572337364, -5.372365467, 4.378...   \n",
       "\n",
       "           Neu_P3_Cz_Latency  ...          Neg_P3_Cz_Latency  \\\n",
       "0  [288, 496, 484, 436, 540]  ...  [516, 336, 464, 328, 464]   \n",
       "1  [520, 300, 448, 544, 352]  ...  [476, 416, 300, 476, 300]   \n",
       "2  [496, 284, 480, 508, 396]  ...  [396, 496, 376, 500, 500]   \n",
       "3  [440, 328, 464, 448, 464]  ...  [380, 468, 544, 360, 412]   \n",
       "4  [480, 468, 476, 540, 456]  ...  [480, 496, 536, 448, 500]   \n",
       "5  [536, 424, 472, 368, 308]  ...  [444, 468, 512, 548, 312]   \n",
       "6  [300, 352, 484, 484, 368]  ...  [364, 404, 448, 480, 460]   \n",
       "\n",
       "                               Neg_LPP_Pz_Peak  \\\n",
       "0      [19.689, 14.803, 20.733, 19.17, 4.5067]   \n",
       "1    [13.516, 9.5852, 15.951, -5.8196, 12.226]   \n",
       "2     [12.613, 11.467, 20.775, 37.825, 21.961]   \n",
       "3  [-5.8567, 19.269, 15.181, 0.026447, 9.8532]   \n",
       "4      [11.552, 7.454, 14.139, 22.385, 30.584]   \n",
       "5    [6.8689, -5.7977, 11.676, 5.4147, 17.426]   \n",
       "6     [16.491, 7.6822, 11.852, 35.217, 20.611]   \n",
       "\n",
       "                                     Neg_LPP_Pz_Mean  \\\n",
       "0  [5.4839868, -2.047257067, 10.16479333, 5.85351...   \n",
       "1  [4.543109067, -5.40825916, 7.187302667, -16.71...   \n",
       "2  [-3.792235733, 0.318505267, 5.570956, 17.74137...   \n",
       "3  [-17.93910267, 5.3266208, 2.012536707, -9.7525...   \n",
       "4  [-1.818389333, -4.315699867, 3.7948524, 8.8629...   \n",
       "5  [-4.407986, -20.41518667, 0.888515333, -8.7165...   \n",
       "6  [1.6644732, -2.4791112, 1.861610987, 13.535673...   \n",
       "\n",
       "          Neg_LPP_Pz_Latency  \\\n",
       "0  [708, 812, 708, 684, 652]   \n",
       "1  [760, 700, 912, 664, 844]   \n",
       "2  [684, 884, 764, 660, 676]   \n",
       "3  [800, 716, 736, 852, 652]   \n",
       "4  [704, 776, 852, 828, 748]   \n",
       "5  [752, 948, 732, 768, 760]   \n",
       "6  [792, 908, 828, 668, 708]   \n",
       "\n",
       "                                     Targ_P3_Cz_Peak  \\\n",
       "0  [13.204, 2.2278, 0.53742, 6.0702, 17.849, 20.9...   \n",
       "1  [15.382, 10.623, 19.378, 13.18, 7.5719, 17.824...   \n",
       "2  [11.223, 10.602, 14.046, 12.654, 22.341, 14.40...   \n",
       "3  [9.3273, 15.912, 9.5864, 14.686, 5.5621, 10.86...   \n",
       "4  [17.776, 10.522, 15.671, 24.699, 23.455, 22.33...   \n",
       "5  [20.765, 13.037, 20.928, 11.307, 24.376, 9.234...   \n",
       "6  [17.259, 21.296, 17.153, 20.551, 13.59, 6.6623...   \n",
       "\n",
       "                                     Targ_P3_Cz_Mean  \\\n",
       "0  [5.490772973, -3.250177861, -9.143535813, -1.1...   \n",
       "1  [3.604507333, 2.952521333, 10.97116267, 4.7187...   \n",
       "2  [2.668363333, 0.992697333, 4.3212716, 2.790468...   \n",
       "3  [-2.16354653, 6.6423792, 0.589601483, 7.341789...   \n",
       "4  [4.825973867, 4.16720756, 3.339279187, 9.86758...   \n",
       "5  [10.30210171, 4.131259147, 10.21560733, 3.7273...   \n",
       "6  [1.868087333, 8.422179853, 11.01720133, 5.5208...   \n",
       "\n",
       "                              Targ_P3_Cz_Latency  \\\n",
       "0  [356, 268, 468, 308, 540, 288, 516, 376, 512]   \n",
       "1  [268, 384, 288, 460, 528, 444, 352, 480, 432]   \n",
       "2  [268, 476, 444, 540, 464, 368, 380, 348, 368]   \n",
       "3  [388, 508, 508, 300, 504, 524, 508, 396, 536]   \n",
       "4  [468, 524, 272, 480, 424, 360, 476, 496, 404]   \n",
       "5  [352, 332, 456, 284, 480, 452, 404, 484, 352]   \n",
       "6  [500, 416, 408, 460, 380, 392, 352, 456, 504]   \n",
       "\n",
       "                                    Targ_LPP_Pz_Peak  \\\n",
       "0  [11.789, 12.805, -11.566, 10.025, 11.778, 20.7...   \n",
       "1  [8.2591, 12.787, 9.4401, 18.837, 8.0799, 7.799...   \n",
       "2  [8.3593, 9.445, -7.4329, 26.584, 4.5528, 12.94...   \n",
       "3  [-2.2704, 20.702, 0.83205, 10.229, 9.0697, 59....   \n",
       "4  [23.705, 9.9586, 15.324, 25.742, 2.6582, 19.15...   \n",
       "5  [15.451, 29.78, 28.229, -2.1441, -5.1174, 32.7...   \n",
       "6  [14.382, 16.7, 11.894, 2.6002, 17.236, 5.3784,...   \n",
       "\n",
       "                                    Targ_LPP_Pz_Mean  \\\n",
       "0  [-0.033728133, -14.79068313, -18.34509333, -1....   \n",
       "1  [-14.98742907, -3.310568201, -8.010133333, 1.9...   \n",
       "2  [-2.17837112, -12.98541112, -24.736936, 10.269...   \n",
       "3  [-11.74187867, 8.154603013, -13.39265827, -7.6...   \n",
       "4  [4.17171284, -6.491420853, -1.072993067, 7.145...   \n",
       "5  [-0.6861636, 5.514461333, 18.69056933, -18.209...   \n",
       "6  [1.581504933, 1.814372133, -3.000958933, -12.0...   \n",
       "\n",
       "                             Targ_LPP_Pz_Latency  \n",
       "0  [672, 944, 716, 920, 924, 828, 768, 784, 832]  \n",
       "1  [916, 824, 932, 936, 784, 696, 856, 680, 908]  \n",
       "2  [876, 760, 820, 740, 820, 948, 936, 676, 864]  \n",
       "3  [924, 828, 872, 936, 660, 836, 848, 740, 852]  \n",
       "4  [680, 876, 780, 700, 872, 708, 904, 908, 720]  \n",
       "5  [876, 852, 900, 704, 704, 928, 812, 916, 928]  \n",
       "6  [792, 880, 800, 664, 768, 896, 748, 808, 708]  \n",
       "\n",
       "[7 rows x 25 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZstatInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fc8ea",
   "metadata": {},
   "source": [
    "### find Voxel dimension by openning one of the image files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42cc2107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 28)\n"
     ]
    }
   ],
   "source": [
    "myZstat=ZstatInfo.loc[(ZstatInfo['Subj']==subj) & (ZstatInfo['Run']==1)]\n",
    "myZstat.reset_index(inplace = True, drop = True)\n",
    "myFile=myZstat['Folder'][0]+myZstat['Neu'][0][0]\n",
    "#print(myFile)\n",
    "data = nib.load(myFile).get_data()\n",
    "voxel_dims = data.shape\n",
    "print(voxel_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7516fd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRadius\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(radius)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_points.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,AllPoints)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.load('Radius'+str(radius)+'_points.npy',AllPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d478ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of shperes: (3, 1, 7)\n",
      "631.951804600074\n"
     ]
    }
   ],
   "source": [
    "# Calculate the spotlights voxels for all points and keep them in AllPoints \n",
    "start = timer()\n",
    "radius = 1 #spheres  radius \n",
    "\n",
    "AllPoints_file='Radius'+str(radius)+'_points.npy'\n",
    "if os.file.exists(AllPoints_file):\n",
    "    np.load(AllPoints_file,AllPoints)\n",
    "else:\n",
    "    tmpPoints = SpherePoints(np.array([26,26,16]) , radius, voxel_dims) #generate a random sphere to find its dimension\n",
    "    print('size of shperes:',tmpPoints.shape)\n",
    "    AllZeroSphere = np.zeros((1,tmpPoints.shape[2]))\n",
    "    AllZeroSpherePoints=np.zeros(tmpPoints.shape)\n",
    "    cnt=0\n",
    "    for myCenter in itertools.product(range(0,voxel_dims[0]), range(0,voxel_dims[1]), range(0,voxel_dims[2])):\n",
    "        #print(myCenter)\n",
    "        myPoints = SpherePoints(np.array(myCenter) , radius, voxel_dims)\n",
    "        if myPoints.shape==(3,1,0): myPoints=AllZeroSpherePoints\n",
    "        if cnt==0:\n",
    "            AllPoints = np.array(myPoints,ndmin=4)\n",
    "            cnt=1\n",
    "        else:\n",
    "            AllPoints = np.concatenate((AllPoints,np.array(myPoints,ndmin=4)),axis=0)\n",
    "    \n",
    "    np.save(AllPoints_file,AllPoints)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05396711",
   "metadata": {},
   "source": [
    "# This code does classification based on spot light search, serial processing, slow. Don't run it\n",
    "start = timer()\n",
    "CLconditions=['Neu','Neg','Targ']\n",
    "radius = 1 #spheres radius\n",
    "\n",
    "\n",
    "##LinearSVC(random_state=0))\n",
    "clf = SVC(kernel='linear',probability=True)\n",
    "pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "\n",
    "subj_list_one=[subj_list[1]]; \n",
    "Nsubj=len(subj_list_one)\n",
    "all_performance = np.zeros(Nsubj)\n",
    "for i_sub, subj in enumerate(subj_list_one):\n",
    "    \n",
    "    ZstatInfoSubj=ZstatInfo.loc[ZstatInfo['Subj']==subj]\n",
    "    \n",
    "    Alldata=LoadAllNii(ZstatInfoSubj,CLconditions) # load Alldata\n",
    "         \n",
    "    DataArgDict= {'AllPoints': AllPoints,\n",
    "              'ZstatInfoSubj':ZstatInfoSubj ,\n",
    "              'CLconditions': CLconditions, \n",
    "              'Alldata': Alldata,\n",
    "              'pipeSpotLight':pipeSpotLight} \n",
    "    SpotLight_performance=np.zeros(AllPoints.shape[0])\n",
    "    for iFeature in range(AllPoints.shape[0]): #iFeature=40836, range(56500,56610):\n",
    "\n",
    "        SpotLight_performance[iFeature]= LoopiFeature(iFeature, AllPoints,ZstatInfoSubj ,CLconditions, Alldata, pipeSpotLight)\n",
    "        \n",
    "end = timer()\n",
    "print(end-start)\n",
    "#SpotLight_performance[56500:56610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fd5093fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Subj Run                                             Folder  \\\n",
      "0  ET_12102013   1  C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/...   \n",
      "\n",
      "                                                 Neu  \\\n",
      "0  [spmT_0001.nii, spmT_0002.nii, spmT_0003.nii, ...   \n",
      "\n",
      "                                                 Neg              Pos  \\\n",
      "0  [spmT_0006.nii, spmT_0007.nii, spmT_0008.nii, ...  [spmT_0011.nii]   \n",
      "\n",
      "                                                Targ Neu_P3_Cz_Peak  \\\n",
      "0  [spmT_0012.nii, spmT_0013.nii, spmT_0014.nii, ...             []   \n",
      "\n",
      "  Neu_P3_Cz_Mean Neu_P3_Cz_Latency  ... Neg_P3_Cz_Latency Neg_LPP_Pz_Peak  \\\n",
      "0             []                []  ...                []              []   \n",
      "\n",
      "  Neg_LPP_Pz_Mean Neg_LPP_Pz_Latency Targ_P3_Cz_Peak Targ_P3_Cz_Mean  \\\n",
      "0              []                 []              []              []   \n",
      "\n",
      "  Targ_P3_Cz_Latency Targ_LPP_Pz_Peak Targ_LPP_Pz_Mean Targ_LPP_Pz_Latency  \n",
      "0                 []               []               []                  []  \n",
      "\n",
      "[1 rows x 25 columns]\n",
      "['spmT_0001.nii', 'spmT_0002.nii', 'spmT_0003.nii', 'spmT_0004.nii', 'spmT_0005.nii']\n",
      "Neu_P3_Cz_Peak\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[226], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m myPoints \u001b[38;5;241m=\u001b[39m SpherePoints(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m15\u001b[39m]) , radius,voxel_dims) \u001b[38;5;66;03m# sample good point\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#[X, Y, Gr]=MVPA_FeatureExtraction(DataArgDict['ZstatInfoSubj'],DataArgDict['CLconditions'],DataArgDict['Alldata'], myPoints,EEG_features) # extract data for classifer\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m [X, Y, Gr]\u001b[38;5;241m=\u001b[39m\u001b[43mMVPA_FeatureExtraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZstatInfoSubj\u001b[49m\u001b[43m,\u001b[49m\u001b[43mCLconditions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAlldata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmyPoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43mEEG_features\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# extract data for classifer\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# SpotPerformance=MVPA_Classification(X,Y,Gr, pipeSpotLight])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#MyZstat[Neu_P3_Cz_Peak][0][MyInd]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[225], line 45\u001b[0m, in \u001b[0;36mMVPA_FeatureExtraction\u001b[1;34m(ZstatInfoSubj, CLconditions, Alldata, myPoints, EEG_features)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(EEG_col)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(MyZstat[EEG_col][\u001b[38;5;241m0\u001b[39m])                    \n\u001b[1;32m---> 45\u001b[0m     EEG_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mMyZstat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEEG_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mMyInd\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEEG_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMyNii\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEEG_data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m X_tmp[MyInd,num_fMRI_features:] \u001b[38;5;241m=\u001b[39mEEG_data\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#myPoints = DataArgDict['AllPoints'][iFeature] \n",
    "myPoints = SpherePoints(np.array([30,30,15]) , radius,voxel_dims) # sample good point\n",
    "\n",
    "#[X, Y, Gr]=MVPA_FeatureExtraction(DataArgDict['ZstatInfoSubj'],DataArgDict['CLconditions'],DataArgDict['Alldata'], myPoints,EEG_features) # extract data for classifer\n",
    "[X, Y, Gr]=MVPA_FeatureExtraction(ZstatInfoSubj,CLconditions,Alldata, myPoints,EEG_features) # extract data for classifer\n",
    "# SpotPerformance=MVPA_Classification(X,Y,Gr, pipeSpotLight])\n",
    "#MyZstat[Neu_P3_Cz_Peak][0][MyInd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB_04152014\n"
     ]
    }
   ],
   "source": [
    "# This code does classification based on spot light search, parallel processing, fast\n",
    "CLconditions=['Neu','Neg','Targ']\n",
    "\n",
    "\n",
    "##LinearSVC(random_state=0))\n",
    "clf = SVC(kernel='linear',probability=True)\n",
    "pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "\n",
    "subj_list_one=[subj_list[1]]; \n",
    "Nsubj=len(subj_list_one)\n",
    "# Nsubj=len(subj_list)\n",
    "all_performance = np.zeros(Nsubj)\n",
    "for i_sub, subj in enumerate(subj_list_one):#subj_list):\n",
    "    if (subj=='ET_12102013') & (radius==2): \n",
    "        continue  \n",
    "    print(subj)\n",
    "    start = timer()\n",
    "\n",
    "    ZstatInfoSubj=ZstatInfo.loc[ZstatInfo['Subj']==subj]\n",
    "    Zstattmp=ZstatInfoSubj.loc[ZstatInfoSubj['Run']==1]\n",
    "    Zstattmp.reset_index(inplace = True, drop = True)\n",
    "    myFiletmp=Zstattmp['Folder'][0]+Zstattmp['Neg'][0][0] # load a sample file to extract file format\n",
    "    \n",
    "    myimg_affine=nib.load(myFiletmp).affine\n",
    "\n",
    "    Alldata=LoadAllNii(ZstatInfoSubj,CLconditions) # load Alldata\n",
    "         \n",
    "    DataArgDict= {'AllPoints': AllPoints,\n",
    "              'ZstatInfoSubj':ZstatInfoSubj ,\n",
    "              'CLconditions': CLconditions, \n",
    "              'Alldata': Alldata,\n",
    "              'pipeSpotLight':pipeSpotLight} \n",
    "    SpotLight_performance=np.zeros(AllPoints.shape[0])\n",
    "    \n",
    "    aa1= range(AllPoints.shape[0])\n",
    "    aa2=[DataArgDict]*len(aa1)\n",
    "    aa=[*zip(aa1, aa2)]\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        pool = Pool(multiprocessing.cpu_count()-2)\n",
    "        resultsN = pool.map(multi_run_wrapperLoopiFeatureDict,aa)\n",
    "\n",
    "        resultsN=np.array(resultsN).reshape(voxel_dims)\n",
    "\n",
    "        nft_img = nib.Nifti1Image(resultsN, myimg_affine)  # save based on the sample file format\n",
    "        OutFile='C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/MRI_data/Analysis/MVPA/SpotlightR'+str(radius)+'/MVPA_'+subj+'.nii.gz'\n",
    "        nib.save(nft_img, OutFile)\n",
    "\n",
    "    end = timer()\n",
    "    print(end-start)\n",
    "# print(resultsN[56500:56510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5db7433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ET_12102013']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87c70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET_12102013\n",

     ]
    }
   ],
   "source": [
    "# This code does classification based on spot light search, serial processing (for trouble shooting)\n",
    "CLconditions=['Neu','Neg','Targ']\n",
    "\n",
    "\n",
    "##LinearSVC(random_state=0))\n",
    "clf = SVC(kernel='linear',probability=True)\n",
    "pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "\n",
    "# subj_list_one=[subj_list[1]]; \n",
    "# Nsubj=len(subj_list_one)\n",
    "Nsubj=1#len([subj_list[6]])\n",
    "all_performance = np.zeros(Nsubj)\n",
    "for i_sub, subj in enumerate(subj_list):#([subj_list[6]]):\n",
    "    print(subj)\n",
    "    start = timer()\n",
    "\n",
    "    ZstatInfoSubj=ZstatInfo.loc[ZstatInfo['Subj']==subj]\n",
    "    Zstattmp=ZstatInfoSubj.loc[ZstatInfoSubj['Run']==1]\n",
    "    Zstattmp.reset_index(inplace = True, drop = True)\n",
    "    myFiletmp=Zstattmp['Folder'][0]+Zstattmp['Neg'][0][0]\n",
    "    \n",
    "    myimg_affine=nib.load(myFiletmp).affine\n",
    "\n",
    "    Alldata=LoadAllNii(ZstatInfoSubj,CLconditions) # load Alldata\n",
    "         \n",
    "    DataArgDict= {'AllPoints': AllPoints,\n",
    "              'ZstatInfoSubj':ZstatInfoSubj ,\n",
    "              'CLconditions': CLconditions, \n",
    "              'Alldata': Alldata,\n",
    "              'pipeSpotLight':pipeSpotLight,\n",
    "              'EEG_features':EEG_features #Eneter None or just delete this line for fMRI only MVPA\n",
    "                 } \n",
    "    SpotLight_performance=np.zeros(AllPoints.shape[0])\n",
    "    \n",
    "#     aa1= range(AllPoints.shape[0])\n",
    "#     aa2=[DataArgDict]*len(aa1)\n",
    "#     aa=[*zip(aa1, aa2)]\n",
    "\n",
    "    resultsN = np.zeros(AllPoints.shape[0])\n",
    "    for iFeature in range(AllPoints.shape[0]): #iFeature=40836, range(56500,56610):\n",
    "\n",
    "        resultsN[iFeature]= LoopiFeatureDict(iFeature, DataArgDict)\n",
    "    \n",
    "    resultsN=np.array(resultsN).reshape(voxel_dims)\n",
    "\n",
    "    nft_img = nib.Nifti1Image(resultsN, myimg_affine)\n",
    "    OutFile='C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/MRI_data/Analysis/MVPA/SpotlightR'+str(radius)+'/MVPA_'+subj+'.nii.gz'\n",
    "    nib.save(nft_img, OutFile)\n",
    "\n",
    "    end = timer()\n",
    "    print(end-start)\n",
    "# print(resultsN[56500:56510])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec6807e",
   "metadata": {},
   "source": [
    "If it is needed to modify a funciton and relaod it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f8d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del multi_run_wrapperLoopiFeatureDict\n",
    "#from MVPA_func import multi_run_wrapperLoopiFeatureDict\n",
    "multi_run_wrapperLoopiFeatureDict = reload(sys.modules[\"MVPA_func\"]).multi_run_wrapperLoopiFeatureDict  # reload() returns the new module\n",
    "LoopiFeatureDict = reload(sys.modules[\"MVPA_func\"]).LoopiFeatureDict  # reload() returns the new module\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a0d7b8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this file, MVPA is applied on Z-stat files from first level analysis I have done on naive space, ART applied images, with each stimuli giving one Z-stat image.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595ae782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import glob\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600e07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MVPA_func import SpherePoints, SphereValue, LoadAllNii, FeautrExtraction, Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c3d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45604e83",
   "metadata": {},
   "source": [
    "### Load subject list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfba78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list_file='C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/subj_simultaneous.txt'\n",
    "subj_list=list()\n",
    "f = open(subj_list_file, 'r')\n",
    "line=f.readline()\n",
    "while line:\n",
    "    subj_list.append(line[0:-1])\n",
    "    oldline=line\n",
    "    line = f.readline()\n",
    "subj_list.pop()\n",
    "subj_list.append(oldline)\n",
    "f.close()\n",
    "Nsubj=len(subj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3db6b",
   "metadata": {},
   "source": [
    "### Load SPM.mat to extract experiment info\n",
    "This cell loads spm.mat file for each participant and from the data, extracts the number of runs, the path for each stat file, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da5fcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: AB_04152014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: AM_05082014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: CJ_06052014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: CS_04162014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: DH_05142014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: DS_12132013\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "   loading SPM.mat for run06...\n",
      "   loading SPM.mat for run07...\n",
      "   loading SPM.mat for run08...\n",
      "Participant: ET_12102013\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "   loading SPM.mat for run06...\n",
      "   loading SPM.mat for run07...\n",
      "   loading SPM.mat for run08...\n",
      "Participant: JK_04252014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: KK_04152014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: MB_04252014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: MG_04152014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: ML_05122014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: MM_05132014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: NB_05012014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: NJM_05142014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: PD_04162014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: RS_04162014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: RS_12102013\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "   loading SPM.mat for run06...\n",
      "   loading SPM.mat for run07...\n",
      "   loading SPM.mat for run08...\n",
      "Participant: SA_05162014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: TD_05012014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "Participant: TH_12172013\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n",
      "   loading SPM.mat for run06...\n",
      "   loading SPM.mat for run07...\n",
      "   loading SPM.mat for run08...\n",
      "Participant: TP_05162014\n",
      "   loading SPM.mat for run01...\n",
      "   loading SPM.mat for run02...\n",
      "   loading SPM.mat for run03...\n",
      "   loading SPM.mat for run04...\n",
      "   loading SPM.mat for run05...\n"
     ]
    }
   ],
   "source": [
    "# note: I don't know why the last item is repeated! but it doesn't make a misatke\n",
    "\n",
    "conditions=['Neu','Neg','Pos','Targ']\n",
    "ZstatInfo=pd.DataFrame(columns=['Subj','Run','Folder']+conditions)\n",
    "for subj in subj_list:\n",
    "    print('Participant: '+subj)\n",
    "    # Zstat files and their condisitons are in SPM filesWe repeat loading in the dataframe to avoid dividing the onsets by 2 multiple times ...\n",
    "    SubjSPMFolder='C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/MRI_data/Analysis/SPM/'+subj+'/3cond_dist2/'\n",
    "    os.path.isdir(SubjSPMFolder)\n",
    "    myZstat=[]\n",
    "    \n",
    "    nRuns = len(os.listdir(SubjSPMFolder))\n",
    "    iRuns = 0\n",
    "    for myRun in os.listdir(SubjSPMFolder):\n",
    "        ZstatInfotmp=pd.DataFrame(columns=ZstatInfo.columns,index=[0])\n",
    "        ZstatInfotmp['Subj'][0]=subj\n",
    "        \n",
    "        RunSubjSPM=SubjSPMFolder+myRun+'/SPM.mat'\n",
    "        ZstatInfotmp['Folder'][0]=SubjSPMFolder+myRun+'/'\n",
    "\n",
    "        print('   loading SPM.mat for '+myRun+'...')\n",
    "        mat = loadmat(RunSubjSPM)\n",
    "        mdata=mat['SPM'][0,0]\n",
    "        ndata=mdata['Sess'][0,0]\n",
    "        odata=ndata['U']\n",
    "        pdata=odata['name'][0]\n",
    "        ZstatNames=[pdata[i][0,0][0] for i in range(len(pdata))]\n",
    "        myZstat.append(ZstatNames)\n",
    "\n",
    "        ZstatInfotmp['Run'][0]=iRuns+1\n",
    "        old_ind=len(myZstat[0])+1\n",
    "        for iCond in reversed(conditions):    \n",
    "            Start_ind=myZstat[0].index(iCond+'_1')+1\n",
    "            #print(Start_ind)\n",
    "            ZstatInfotmp[iCond][0]=['spmT_'+str(val).zfill(4)+'.nii' for val in list(range(Start_ind, old_ind))]#list(range(Start_ind, old_ind))\n",
    "            old_ind=Start_ind\n",
    "        ZstatInfo=ZstatInfo.append(ZstatInfotmp,ignore_index=True)\n",
    "        iRuns = iRuns+1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c495c4",
   "metadata": {},
   "source": [
    "### find Voxel dimension by openning one of the image files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42cc2107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users/user/Documents/Reyhaneh/EEG+fMRI/EO/MRI_data/Analysis/SPM/TP_05162014/3cond_dist2/run01/spmT_0001.nii\n",
      "(64, 64, 28)\n"
     ]
    }
   ],
   "source": [
    "MyZstat=ZstatInfo.loc[(ZstatInfo['Subj']==subj) & (ZstatInfo['Run']==1)]\n",
    "MyZstat.reset_index(inplace = True, drop = True)\n",
    "MyFile=MyZstat['Folder'][0]+MyZstat['Neu'][0][0]\n",
    "print(MyFile)\n",
    "data = nib.load(MyFile).get_data()\n",
    "voxel_dims = data.shape\n",
    "print(voxel_dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f4cfa",
   "metadata": {},
   "source": [
    "If it is needed to modify a funciton and relaod it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fa8645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload #import function \"reload\"\n",
    "import sys\n",
    "SpherePoints = reload(sys.modules[\"MVPA_func\"]).SpherePoints  # reload() returns the new module\n",
    "#from MVPA_func reload SpherePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800e76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "radius = 1 #spheres have radius 2\n",
    "tmpPoints = SpherePoints(np.array([26,26,16]) , radius, voxel_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61d478ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308.3831950998865\n"
     ]
    }
   ],
   "source": [
    "# Calculate the spotlights voxels for all points and keep them in AllPoints \n",
    "start = timer()\n",
    "\n",
    "radius = 1 #spheres have radius 2\n",
    "tmpPoints = SpherePoints(np.array([26,26,16]) , radius, voxel_dims)\n",
    "AllZeroSphere = np.zeros((1,tmpPoints.shape[2]))\n",
    "AllZeroSpherePoints=np.zeros(tmpPoints.shape)\n",
    "cnt=0\n",
    "for MyCenter in itertools.product(range(0,voxel_dims[0]), range(0,voxel_dims[1]), range(0,voxel_dims[2])):\n",
    "    #print(MyCenter)\n",
    "    myPoints = SpherePoints(np.array(MyCenter) , radius, voxel_dims)\n",
    "    if myPoints.shape==(3,1,0): myPoints=AllZeroSpherePoints\n",
    "    if cnt==0:\n",
    "        AllPoints = np.array(myPoints,ndmin=4)\n",
    "        cnt=1\n",
    "    else:\n",
    "        AllPoints = np.concatenate((AllPoints,np.array(myPoints,ndmin=4)),axis=0)\n",
    "#     if myPoints.shape!=(3,1,0): sphereVal = data[myPoints[0],myPoints[1],myPoints[2]]\n",
    "#     else: sphereVal = AllZeroSphere\n",
    "        \n",
    "#    if myPoints.shape!=(0,): sphereVal = SphereValue(myPoints,data)\n",
    "#     if sphereVal.shape!=(0,): sphereValOut=\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "119cacb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GroupKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# myPoints = SpherePoints(np.array([30,30,15]) , radius) # sample good point\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         [X, Y, Gr]\u001b[38;5;241m=\u001b[39mFeautrExtraction(ZstatInfoSubj,CLconditions,Alldata, myPoints) \u001b[38;5;66;03m# extract data for classifer\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m         SpotPerformance\u001b[38;5;241m=\u001b[39m\u001b[43mClassification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43mGr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeSpotLight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m         SpotLight_performance[iFeature]\u001b[38;5;241m=\u001b[39m SpotPerformance\n\u001b[0;32m     32\u001b[0m end \u001b[38;5;241m=\u001b[39m timer()\n",
      "File \u001b[1;32m~\\Documents\\Reyhaneh\\EEG+fMRI\\Codes\\Python\\MVPA_func.py:131\u001b[0m, in \u001b[0;36mClassification\u001b[1;34m(X, y, Gr, pipeSpotLight)\u001b[0m\n\u001b[0;32m    128\u001b[0m '''Performe classification on voxed data'''\n\u001b[0;32m    129\u001b[0m SpotPerformance = 0;\n\u001b[0;32m    130\u001b[0m if (np.any(X)): # perform classifier if values of X are not all zero\n\u001b[1;32m--> 131\u001b[0m     # print(Gr)\n\u001b[0;32m    132\u001b[0m     gkf = GroupKFold(n_splits=iRun) # leave one out, initialize GroupKFold with Nrun splits\n\u001b[0;32m    133\u001b[0m     performance_this_fold = np.zeros(gkf.n_splits)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GroupKFold' is not defined"
     ]
    }
   ],
   "source": [
    "# This code does classification based on spot light search\n",
    "start = timer()\n",
    "CLconditions=['Neu','Neg','Targ']\n",
    "radius = 1 #spheres radius\n",
    "\n",
    "\n",
    "##LinearSVC(random_state=0))\n",
    "clf = SVC(kernel='linear',probability=True)\n",
    "pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "\n",
    "subj_list_one=[subj_list[1]]; \n",
    "Nsubj=len(subj_list_one)\n",
    "all_performance = np.zeros(Nsubj)\n",
    "for i_sub, subj in enumerate(subj_list_one):\n",
    "    \n",
    "    ZstatInfoSubj=ZstatInfo.loc[ZstatInfo['Subj']==subj]\n",
    "    \n",
    "    Alldata=LoadAllNii(ZstatInfoSubj,CLconditions) # load Alldata\n",
    "         \n",
    "     \n",
    "    SpotLight_performance=np.zeros(AllPoints.shape[0])\n",
    "    for iFeature in range(56500,56510):#range(AllPoints.shape[0]): #iFeature=40836\n",
    "        myPoints = AllPoints[iFeature] \n",
    "        # myPoints = SpherePoints(np.array([30,30,15]) , radius) # sample good point\n",
    "\n",
    "        [X, Y, Gr]=FeautrExtraction(ZstatInfoSubj,CLconditions,Alldata, myPoints) # extract data for classifer\n",
    "        SpotPerformance=Classification(X,Y,Gr, pipeSpotLight)\n",
    "\n",
    "        SpotLight_performance[iFeature]= SpotPerformance\n",
    "        \n",
    "\n",
    "end = timer()\n",
    "print(end-start)\n",
    "SpotLight_performance[56500:56510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f4ec63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m pipeSpotLight \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, clf)])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#pipe.fit(X_train, Y_train)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m pipeSpotLight\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, Y_train)\n\u001b[0;32m      8\u001b[0m preds \u001b[38;5;241m=\u001b[39m pipeSpotLight\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m      9\u001b[0m pipeSpotLight\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "##LinearSVC(random_state=0))\n",
    "clf = SVC(kernel='linear',probability=True)\n",
    "pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('clf', clf)])\n",
    "\n",
    "#pipeSpotLight = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "#pipe.fit(X_train, Y_train)\n",
    "pipeSpotLight.fit(X_train, Y_train)\n",
    "preds = pipeSpotLight.predict(X_train)\n",
    "pipeSpotLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6e8e7da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[30., 31., 31., 31., 31., 31., 32.]],\n",
       "\n",
       "       [[33., 32., 33., 33., 33., 34., 33.]],\n",
       "\n",
       "       [[24., 24., 23., 24., 25., 24., 24.]]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(3,6):\n",
    "    print(i)\n",
    "iFeature=56500\n",
    "AllPoints[iFeature] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "f46d6310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.503125  , 0.58993056, 0.47204861, 0.        , 0.        ,\n",
       "       0.41822917, 0.56614583, 0.49392361, 0.62256944, 0.58732639])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpotLight_performance[56500:56510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "fdaa2d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48888889, 0.57986111, 0.45486111, 0.        , 0.        ,\n",
       "       0.47638889, 0.55972222, 0.50329861, 0.625     , 0.58854167])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78cf7e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neu       0.55      0.75      0.63         8\n",
      "         Neg       0.33      0.12      0.18         8\n",
      "        Targ       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.58      0.62      0.58        28\n",
      "weighted avg       0.62      0.68      0.63        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, preds,target_names=CLconditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f10149",
   "metadata": {},
   "source": [
    "This code generates sphere around around a center and predefined sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c64c81c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  2,  0],\n",
       "       [ 5,  1,  2],\n",
       "       [ 0,  0, 12]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(accuracy_score(Y_test, preds))\n",
    "confusion_matrix(Y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bdce990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 3. 2. 1. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3.]\n",
      "Accuracy test: 0.68\n",
      "Pairwise AUC:  0.59375 1.0 0.875\n",
      "pairwise AUC mean 0.8392857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.80989583, 0.87326389, 0.81336806, 0.81857639, 0.73871528])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mypreds=[2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 1, 3]# 4th fold\n",
    "Mypreds=preds#5th fold\n",
    "print(Mypreds)\n",
    "print(Y_test)\n",
    "print(\"Accuracy test: %.2f\" % (Mypreds == Y_test).mean())\n",
    "Y12, P12 =Y_test[0:16], Mypreds[0:16]\n",
    "Y13, P13=np.concatenate((Y_test[0:8],Y_test[16:])), np.concatenate((Mypreds[0:8],Mypreds[16:]))\n",
    "Y23, P23=Y_test[8:], Mypreds[8:]\n",
    "ROC12=roc_auc_score(Y12,P12)\n",
    "ROC13=roc_auc_score(Y13,P13)\n",
    "ROC23=roc_auc_score(Y23,P23)\n",
    "\n",
    "print('Pairwise AUC: ',ROC12,ROC13,ROC23)\n",
    "print('pairwise AUC averaged mean:',ROC12*16/56+ROC13*20/56+ROC23*20/56)\n",
    "performance_this_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3809c46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 2. 1. 1. 1. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(Y13)\n",
    "print(P13)\n",
    "ROC13=roc_auc_score(Y13,P13)\n",
    "print(ROC13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b7cf5722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7196180555555555"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select100best = SelectKBest(f_classif, k=100)\n",
    "\n",
    "##\n",
    "#clf=MultiOutputClassifier(SVC(kernel='linear'))\n",
    "clf = SVC(kernel='linear',probability=True)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('ufs', select100best), ('clf', clf)])\n",
    "pipe.fit(X_train, Y_train)\n",
    "pipe.decision_function(X_test)\n",
    "pipe.predict_proba(X_test)\n",
    "# roc_auc_score(Y_test, pipe.predict_proba(X_test),  multi_class='ovr')\n",
    "roc_auc_score(Y_test, pipe.predict_proba(X_test),  multi_class='ovo')\n",
    "\n",
    "#clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "187f1da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct labels: [1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3.]\n",
      "Predicted labels: [1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 3. 2. 1. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3.]\n",
      "Accuracy test: 0.68\n"
     ]
    }
   ],
   "source": [
    "print('Correct labels:',Y_test)\n",
    "print('Predicted labels:',preds)\n",
    "print(\"Accuracy test: %.2f\" % (preds == Y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "33fd559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n",
    "yt=clf.predict_proba(X)\n",
    "roc_auc_score(y, yt, multi_class='ovr')\n",
    "np.sum(clf.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8bdc8fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracty: 0.6571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Try out different estimators below (call fit and predict on X and y!)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X, Y)\n",
    "y_hat=lda.predict(X)\n",
    "print('accuracty: '+ str(accuracy_score(Y, y_hat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7ddfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old file, no need to run it\n",
    "# Calculate the spotlights voxels for all feasible voxel. check which one is faster\n",
    "start = timer()\n",
    "iSpot=0\n",
    "#for MyCenter in itertools.product(range(radius,voxel_dims[0]-radius), range(radius,voxel_dims[1]-radius), range(radius,voxel_dims[2]-radius)):\n",
    "for MyCenter in itertools.product(range(0,voxel_dims[0]), range(0,voxel_dims[1]), range(0,voxel_dims[2])):\n",
    "    #print(MyCenter)\n",
    "    myPoints = SpherePoints(np.array(MyCenter) , radius)\n",
    "    if myPoints.shape==(3,1,0): myPoints=AllZeroSpherePoints\n",
    "    if iSpot==0:\n",
    "        SpotPoints=np.array([myPoints])\n",
    "        iSpot=1\n",
    "    else:\n",
    "        SpotPoints=np.append(SpotPoints,np.array([myPoints]), axis=0)\n",
    "    \n",
    "\n",
    "#voxel_dimCut=[voxel_dims[0]-2*radius,voxel_dims[1]-2*radius,voxel_dims[2]-2*radius]\n",
    "# for idata in range(X.shape[0]):\n",
    "#     dataN=X[idata].reshape(voxel_dims,order='C')\n",
    "#     if myPoints.shape!=(3,1,0): sphereVal = dataN[myPoints[0],myPoints[1],myPoints[2]]\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
